{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "from llama_index.core.storage.chat_store import SimpleChatStore\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    level=logging.DEBUG,\n",
    ")\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "space_name = \"policies_aa\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"name\"\n",
    "]  # default, could be omit if create from an empty kg\n",
    "tags = [\"entity\"]  # default, could be omit if create from an empty kg\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"./data/index/policies_aa\",\n",
    "    graph_store=graph_store\n",
    ")\n",
    "\n",
    "kg_index = load_index_from_storage(\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chat_store = SimpleChatStore()\n",
    "\n",
    "chat_memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit=3000,\n",
    "    chat_store=chat_store,\n",
    "    chat_store_key=\"user1\",\n",
    ")\n",
    "\n",
    "chat_engine = kg_index.as_chat_engine(memory=chat_memory)\n",
    "\n",
    "question = \"What is the fee for a checked bag on American Airlines?\"\n",
    "response = chat_engine.chat(question)\n",
    "display(Markdown(f\"<b>Q: {question}<b>\\n\\n<b>A: {response}</b>\"))\n",
    "\n",
    "question_2 = \"I'm flying economy class to Cuba.\"\n",
    "response_2 = chat_engine.chat(question_2)\n",
    "display(Markdown(f\"<b>Q: {question_2}<b>\\n\\n<b>A: {response_2}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
