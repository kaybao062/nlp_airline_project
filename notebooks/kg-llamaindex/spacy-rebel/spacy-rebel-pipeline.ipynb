{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using REBEL model to extract entities and relationships instead of LLM.\n",
    "\n",
    "Follow along: https://colab.research.google.com/drive/1G6pcR0pXvSkdMQlAK_P-IrYgo-_staxd?usp=sharing#scrollTo=XX_GxhusPZR8\n",
    "\n",
    "Install Nebula Graph: `curl -fsSL nebula-up.siwei.io/install.sh | bash`\n",
    "\n",
    "Also follow along: https://colab.research.google.com/drive/1tLjOg2ZQuIClfuWrAC2LdiZHCov8oUbs#scrollTo=kkHpLzEuYo_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline\n",
    "from llama_index.core import (\n",
    "    Document,\n",
    "    KnowledgeGraphIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup nebula graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Pool Created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llamaindex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>policies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name\n",
       "0  llamaindex\n",
       "1    policies"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext ngql\n",
    "%ngql --address 127.0.0.1 --port 9669 --user root --password nebula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "CREATE SPACE policies_2(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);\n",
    "USE policies_2;\n",
    "CREATE TAG entity(name string);\n",
    "CREATE EDGE relationship(relationship string);\n",
    "CREATE TAG INDEX entity_index ON entity(name(256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_name = \"policies_2\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "]  # default, could be omit if create from an empty kg\n",
    "tags = [\"entity\"]  # default, could be omit if create from an empty kg\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load review documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded policies: (100, 4)\n"
     ]
    }
   ],
   "source": [
    "def load_policies(\n",
    "    file: str = \"../../data/clean/policy_chunks.csv\",\n",
    "    start_index: int = 0,\n",
    "    limit: int = 100,\n",
    "):\n",
    "    # load dataframe:\n",
    "    df = pd.read_csv(file)[start_index:start_index + limit]\n",
    "    print(f\"Loaded policies: {df.shape}\")\n",
    "    df[\"Content\"] = df.apply(lambda row: f\"{row['Header 1']}\\n{row['Header 2']}\\n{row['Concat']}\".replace(\"\\n\\n\", \"\\n\").replace(\"\\n\\n\", \"\\n\"), axis=1)\n",
    "    documents = [\n",
    "        Document(\n",
    "            text=row[\"Content\"],\n",
    "            metadata={\n",
    "                \"airline\": row[\"Airline\"],\n",
    "                \"title\": row[\"Header 1\"],\n",
    "                \"type\": row[\"Header 2\"],\n",
    "            }\n",
    "        )\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    return documents\n",
    "    # splitter = SentenceSplitter(\n",
    "    #    chunk_size=200,\n",
    "    #    chunk_overlap=0,\n",
    "    #    paragraph_separator=\"\\n\\n\"\n",
    "    #)\n",
    "    # \n",
    "    #nodes = splitter.get_nodes_from_documents(documents)\n",
    "    # return nodes\n",
    "\n",
    "policies = load_policies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load extract triplets functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the generated text and extract the triplets\n",
    "# Rebel outputs a specific format. This code is mostly copied from the model card!\n",
    "\n",
    "triplet_extractor = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"Babelscape/rebel-large\",\n",
    "    tokenizer=\"Babelscape/rebel-large\",\n",
    "    device=-1,\n",
    "    temperature=0.3,\n",
    "    top_p=0.2,\n",
    "    # do_sample=True,\n",
    ") # , device=\"cuda:0\")\n",
    "\n",
    "\n",
    "def extract_triplets(input_text):\n",
    "    text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(input_text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])[0]\n",
    "\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and subject in input_text and relation != '' and relation in input_text and object_ != '' and object_ in input_text:\n",
    "        triplets.append((subject.strip(), relation.strip(), object_.strip()))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0,\n",
    "    paragraph_separator=\"\\n\\n\"\n",
    ")\n",
    " \n",
    "nodes = splitter.get_nodes_from_documents(policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0].text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_extractor.tokenizer.batch_decode([triplet_extractor(nodes[0].text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_triplets(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_components\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.add_pipe(\"rebel\", after=\"senter\", config={\n",
    "    'device':0, # Number of the GPU, -1 if want to use CPU\n",
    "    'model_name':'Babelscape/rebel-large'} # Model used, will default to 'Babelscape/rebel-large' if not given\n",
    "    )\n",
    "# input_sentence = \"Gràcia is a district of the city of Barcelona, Spain. It comprises the neighborhoods of Vila de Gràcia, Vallcarca i els Penitents, El Coll, La Salut and Camp d'en Grassot i Gràcia Nova. Gràcia is bordered by the districts of Eixample to the south, Sarrià-Sant Gervasi to the west and Horta-Guinardó to the east. A vibrant and diverse enclave of Catalan life, Gràcia was an independent municipality for centuries before being formally annexed by Barcelona in 1897 as a part of the city's expansion.\"\n",
    "input_sentence = nodes[0].text \n",
    "\n",
    "doc = nlp(input_sentence)\n",
    "doc_list = nlp.pipe([input_sentence])\n",
    "for value, rel_dict in doc._.rel.items():\n",
    "    print(f\"{value}: {rel_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([doc for doc in policies if doc.metadata[\"airline\"] == \"aa\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Graph Index Query Engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.chunk_size = 256\n",
    "Settings.node_parser = SentenceSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    paragraph_separator=\"\\n\\n\"\n",
    ")\n",
    "# Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "# Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
    "# Settings.num_output = 512\n",
    "# Settings.context_window = 3900\n",
    "\n",
    "documents = load_policies()\n",
    "# index = KnowledgeGraphIndex.from_documents(documents, kg_triplet_extract_fn=extract_triplets)\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=25,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    "    # kg_triplet_extract_fn=extract_triplets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check it was loaded to Nebula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ngql USE llamaindex;\n",
    "%ngql MATCH ()-[e]->() RETURN e LIMIT 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in index.as_retriever().retrieve(\"What does Singapore Airlines offer?\"):\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.as_query_engine().query(\"Tell me about Singapore Airlines\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.as_query_engine().query(\"Tell me about Singapore Airlines\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesnt seem to be from the KG..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import KnowledgeGraphQueryEngine\n",
    "\n",
    "\n",
    "nl2kg_query_engine = KnowledgeGraphQueryEngine(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.langchain import LangchainEmbedding\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_airline_project-fCxuAmfF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
