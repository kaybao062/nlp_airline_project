{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow along: https://python.langchain.com/docs/use_cases/graph/constructing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "\n",
    "\n",
    "# initialize env vars - load credentials\n",
    "load_dotenv()\n",
    "\n",
    "# initialize graph db:\n",
    "graph = Neo4jGraph()\n",
    "\n",
    "# initialize llm:\n",
    "# llm = ChatFireworks(\n",
    "#    model=\"accounts/fireworks/models/firefunction-v1\",\n",
    "#    max_tokens=5_000,\n",
    "    # model=\"accounts/fireworks/models/llama-v3-70b-instruct\",\n",
    "    # prompt_truncate_len=3_000,\n",
    "    # response_format={\"type\": \"json_object\"},\n",
    "    # context_length_exceeded_behavior=\"error\",\n",
    "# )\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#    base_url=\"https://api.together.xyz/v1\",\n",
    "#    api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
    "#    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "#)\n",
    "\n",
    "# llm = ChatVertexAI(model_name=\"gemini-pro\")\n",
    "\n",
    "#llm = ChatOpenAI(\n",
    "#    temperature=0,\n",
    "#    # model_name=\"gpt-4-0125-preview\",\n",
    "#    model_name=\"gpt-3.5-turbo-instruct\",\n",
    "# )\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    )\n",
    "\n",
    "# initialize graph transformer:\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    # alternative options: (these are just examples)\n",
    "    # allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    # allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read reviews, prepare reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(\n",
    "    file: str = \"../data/clean/cleaned_reviews.csv\",\n",
    "    start_index: int = 0,\n",
    "    limit: int = 100,\n",
    "):\n",
    "    # load dataframe:\n",
    "    reviews_df = pd.read_csv(file)[start_index:start_index + limit]\n",
    "    print(f\"Loaded reviews: {reviews_df.shape}\")\n",
    "    reviews_df[\"Content\"] = reviews_df.apply(lambda row: f\"{row['Review Title']}\\n{row['Review Content']}\", axis=1)\n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total reviews: 28,950. Average time per 10 queries: 1m6s. Expected time for 28,9k: 60 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform reviews to nodes and relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def convert_to_graph_documents(df: pd.DataFrame, page_content_column: str = \"Content\"):\n",
    "    # graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "    loader = DataFrameLoader(df, page_content_column=page_content_column)\n",
    "    documents = loader.load()\n",
    "    # return  llm_transformer.convert_to_graph_documents(documents)\n",
    "    graph_documents = []\n",
    "    for doc in documents:\n",
    "        try:\n",
    "            # fireworks doesnt always return valid json\n",
    "            graph_documents += llm_transformer.convert_to_graph_documents([doc])\n",
    "        except:\n",
    "            graph_documents += [None]\n",
    "    return graph_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See example graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Nodes: {graph_documents[0].nodes}\")\n",
    "# print(f\"Relationships: {graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store dataframe with graph temporarily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_graph_locally(\n",
    "    df: pd.DataFrame,\n",
    "    docs: list,\n",
    "    path: str,\n",
    "):\n",
    "    df[\"graph\"] = [gd.json() if gd is not None else None for gd in docs]\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing to graph database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteratively load these in chunks because, well, there's... a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# earlier:\n",
    "# combination of fireworks and others\n",
    "\n",
    "# together.ai: mixtral \n",
    "#start_index = 300\n",
    "#limit = 500\n",
    "#chunk_size = 10\n",
    "\n",
    "start_index = 2000\n",
    "limit = 10000\n",
    "chunk_size = 10\n",
    "\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "graph_docs = []\n",
    "\n",
    "reviews_df = load_reviews(start_index=start_index, limit=limit)\n",
    "for idx, chunk_df in enumerate(chunker(reviews_df, chunk_size)):\n",
    "    idx_start = start_index + (idx * chunk_size)\n",
    "    idx_end = start_index + ((idx + 1) * chunk_size)\n",
    "    print(f\"chunk {idx}: {idx_start} -> {idx_end}. {chunk_df.shape}\")\n",
    "\n",
    "    chunk_graph_docs = convert_to_graph_documents(chunk_df)\n",
    "    graph_docs += chunk_graph_docs\n",
    "    print(f\"chunk {idx}: converted\")\n",
    "\n",
    "    store_graph_locally(chunk_df, chunk_graph_docs, f\"../data/transformed/openai/reviews-graph-{idx_start}-{idx_end}.csv\")\n",
    "    print(f\"chunk {idx}: saved to csv\")\n",
    "\n",
    "    chunk_graph_docs = list(filter(None, chunk_graph_docs))\n",
    "    graph.add_graph_documents(chunk_graph_docs)\n",
    "    print(f\"chunk {idx}: saved to neo4j\")\n",
    "    print(f\"move index to: {idx_end}\")\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1180"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_airline_project-fCxuAmfF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
